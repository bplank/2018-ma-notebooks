{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Working with text data, Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "After this notebook you should know:\n",
    "\n",
    "* how to represent text data as features\n",
    "* how to evaluate your ML classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "<small>Tutorial adapted from scikit-learn see [http://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html](http://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html)</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Recap ML 101: What we need\n",
    "\n",
    "1. Data\n",
    "  * input $X$ and output (labels) $Y$ \n",
    "2. Features\n",
    "  * the actual features: how $X$ is decomposed into its parts by the vectorizer/featurizer $\\phi$ --- ** How do we extract features from text data? **\n",
    "3. Model/Algorithm\n",
    "  * the machine learning algorithm used \n",
    "4. Evaluation\n",
    "  * how to measure how good your model is --- ** How do we evaluate our model? **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Extracting features from text data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* IRIS example from last lecture: we were already given the features (do you remember how many those were?)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* In NLP, we typically have many more features, and we typically first need to define **how to represent the text**.\n",
    "    * There is an extra step from the **raw text input** to the actual features that are used: \n",
    "    * This step of extracting features from raw (text) input is called **featurization** or **vectorization**\n",
    "\n",
    "    * It means that we turn the original content into a feature vector, a vector with of numerical values where each dimension of the vector corresponds to a particular **feature**. \n",
    "    \n",
    "Let us look at a concrete example, the Reuters 20 newsgroup dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: Loading the 20 newsgroup dataset\n",
    "\n",
    "This notebook assumes you have downloaded the 20 newsgroup data in a folder called `data` in your current directory (see how-to on the scikit-learn [tutorial website](http://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "categories = ['soc.religion.christian', 'comp.graphics', 'sci.med']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "twenty_train = fetch_20newsgroups(subset='train', categories=categories, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Notice: the data has been shuffled randomly, using a fixed seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['target_names', 'filenames', 'description', 'DESCR', 'target', 'data'])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_train.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['comp.graphics', 'sci.med', 'soc.religion.christian']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_train['target_names']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Lets look at the first document (data instance) in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"From: tbrent@ecn.purdue.edu (Timothy J Brent)\\nSubject: Am I going to Hell?\\nOrganization: Purdue University Engineering Computer Network\\nLines: 12\\n\\nI have stated before that I do not consider myself an atheist, but \\ndefinitely do not believe in the christian god.  The recent discussion\\nabout atheists and hell, combined with a post to another group (to the\\neffect of 'you will all go to hell') has me interested in the consensus \\nas to how a god might judge men.  As a catholic, I was told that a jew,\\nbuddhist, etc. might go to heaven, but obviously some people do not\\nbelieve this.  Even more see atheists and pagans (I assume I would be \\nlumped into this category) to be hellbound.  I know you believe only\\ngod can judge, and I do not ask you to, just for your opinions.\\n\\nThanks,\\n-Tim\\n\""
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_train['data'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "What is $X$? \n",
    "\n",
    "The data ($X$) is still in raw (original) input format, no **featurizer** has yet been applied to the data. It is still an entire \"chunk\" of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "What are the $Y$s? \n",
    "\n",
    "As we saw already in the IRIS dataset, target (classes/labels/categories) are encoded as integers. These are the labels we are going to predict, they correspond to the target_names given above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 0, ..., 0, 2, 2])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_train['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We can get the original names back, lets say we want to look at the first 10 data instances and get their category/label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "soc.religion.christian = 2\n",
      "comp.graphics = 0\n",
      "comp.graphics = 0\n",
      "comp.graphics = 0\n",
      "comp.graphics = 0\n",
      "comp.graphics = 0\n",
      "soc.religion.christian = 2\n",
      "comp.graphics = 0\n",
      "comp.graphics = 0\n",
      "sci.med = 1\n"
     ]
    }
   ],
   "source": [
    "for target_idx in twenty_train['target'][:10]:\n",
    "    print(twenty_train.target_names[target_idx], \"=\", target_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Extracting features from text data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In order to run a machine learning algorithm, we first need to **decompose** the original text data into a **set of features**. This process is called featurization (or extracting features from data). You can imagine it as a process that goes from your raw input to a vector of some fixed size $d$, where each dimension of the vector corresponds to a particular **feature**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"pics/learning.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Bag-of-words \n",
    "\n",
    "A very simple way to decompose the input text is to make a 'bag-of-words' representation. Here we break the input text down into single words, and the feature vector encodes with words it has seen for a given instance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"pics/bow1.png\" width=300>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "For example, the following two instances would be represented in a BOW model as:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"pics/bow2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "You can decide which features to include, maybe not always all words are good predictors for your target variable. For example, in the case of sentiment analysis. We could decide to only use content words and punctuation as features, e.g.,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"pics/bow3.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Note, however, that typically the ML system does not store large feature vectors. In particular, when working with text data **a lot of features in X will be zero**, i.e., only a few words actually occur in a particular instance/example. Storing the long vector would be very inefficient. Thus, internally sklearn keeps a **sparse** representation of the features. See more [here](http://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html).\n",
    "\n",
    "What features to take is crucial for a machine learning system, and can make a big performance difference. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Scikit-learn (sklearn) includes a range of build-in featurizers. We are only looking at a very simple vectorizer for count data, the `CountVectorizer`. But please have a look at more vectorizers available in sklearn/scikit-learn, like `TfIdfVectorizer`, or the custom `DictVectorizer`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### The `CountVectorizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1777, 31638)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vectorizer = CountVectorizer().fit(twenty_train.data) #stop_words=\"english\"\n",
    "X_train_counts = count_vectorizer.transform(twenty_train.data)\n",
    "X_train_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1777"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(twenty_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x31638 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 93 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_counts[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The `CountVectorizer` stores the data in **sparse** matrix format. It contains a `vocabulary` that maps features to their feature numbers. We can get the feature id (number) of a particular feature by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28369"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer.vocabulary_.get(\"the\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The [`CountVectorizer`](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer) has many options. By default it stores the frequency of a word unigram (lowercased), where a word is defined by `token_pattern=u'(?u)\\b\\w\\w+\\b'`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "However, by storing the occurence of a token notice that there is a side effect: longer document will typically have higher average count values, even though they might talk about the same topic, say.  How can we avoid this issue?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "1. Using **binary** (1/0 or on/off) feature values: instead of accounting for frequency, each token gets the same `weight`, it is either present or not. You can achieve binary (indicator) features by setting the `binary` option of the `CountVectorizer` to `binary=True`. \n",
    "\n",
    "2. Using **relative** term frequencies: instead of using the raw counts, divide by the total number of words in a document. Typically, you then want to downplay the importance of features that occur in many documents. This is achieved by weighting the frequency by the inverse document frequency (and hence, tokens that appear in many documents are less important). This is what the `TfIdfTokenizer` is doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1777, 31638)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## using binary feature values\n",
    "count_vectorizer_binary = CountVectorizer(binary=True).fit(twenty_train.data)\n",
    "X_train_counts_binary = count_vectorizer_binary.transform(twenty_train.data)\n",
    "X_train_counts_binary.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**A shortcut - `fit_transform`:** Note that the `sklearn` vectorizers have a shortcut `fit_transform`, this function does the two steps above in one go: `fit` creates the vocabulary from the data, then `transform` is used to convert the raw input data into feature vectors, given the vocabulary. Using `fit_transform` is at times faster.\n",
    "\n",
    "Note, however, that the `fit' function should always only be done on the training data -- otherwise you would create a new vocabulary on your test data and that would skrew things up. You *decide* your features on your training data, and test them then on your development/test data, you don't pick features based on the dev/test set!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Writing your own vectorizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "With the `DictVectorizer` you can add your own features, you have full control.\n",
    "As the name already says it wants a dictionary, where the keys are your feature names and  values are the feature values (binary or frequencies or what you want to use). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Training a classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Now that we have converted our data into features, we can train our classifier to predict the category of a post. Let us try to use a logistic regression classifier, and use a binary word unigram BOW representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "clf = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1777, 31638)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## using binary feature values\n",
    "X_train = CountVectorizer(binary=True).fit_transform(twenty_train.data)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now lets train the classifier and use it to predict the label of a new post. We again need to extract the features from the document, using the vectorizer. Then we can use the classifier to `predict` the label of the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "## train the classifier, and evaluate it on a new document:\n",
    "clf.fit(X_train, twenty_train.target)\n",
    "document = [\"don't believe\"]\n",
    "X_test = count_vectorizer_binary.transform(document)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* **Note** the use of `tranform` here (**not** `fit_transform`). What would have happened if we were to call `fit_transform`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "y_predicted = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2]\n",
      "soc.religion.christian\n"
     ]
    }
   ],
   "source": [
    "print(y_predicted)\n",
    "print(twenty_train.target_names[y_predicted[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Cool! We trained our classifier, using a BOW feature representation (with unigram word features as binary indicator values). In the example above we gave the classifier just a single new test instance. You can also give it a list of examples to classifier, as the following code shows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "documents = [\"the graphic card sucks\", \"health / glucose is ..\", \"the right word\"]\n",
    "X_test = count_vectorizer_binary.transform(documents)\n",
    "y_predicted = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comp.graphics\n",
      "sci.med\n",
      "soc.religion.christian\n"
     ]
    }
   ],
   "source": [
    "for y_hat in y_predicted:\n",
    "    print(twenty_train.target_names[y_hat])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Evaluating performance on the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We want to build a classifier that generalizes, i.e., that it works *beyond* the training data.\n",
    "\n",
    "A classifier generalizes reasonably well if it can predict with acceptable performance on new **unseen** test cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "twenty_test = fetch_20newsgroups(subset='test', categories=categories, shuffle=True, random_state=42)\n",
    "## convert test to vectors\n",
    "X_test = count_vectorizer_binary.transform(twenty_test.data)\n",
    "y_predicted = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* **Accuracy**: out of all predictions, how many are correct\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Evaluating accuracy is easy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.930684699915\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_true = twenty_test.target\n",
    "print(accuracy_score(y_true, y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 93.07 (correct/total: 1101/1183.0)\n"
     ]
    }
   ],
   "source": [
    "# from scratch \n",
    "correct, total = 0, 0.0\n",
    "for gold, pred in zip(y_true,y_predicted):\n",
    "    if gold==pred:\n",
    "        correct+=1\n",
    "    total+=1\n",
    "print(\"Accuracy {0:.2f} (correct/total: {1}/{2})\".format(correct/total*100, correct, total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Or, alternatively, even easier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93068469991546909"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.mean(y_true == y_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "However, accuracy alone (= how many predictions are correct, out of all predictions) often tells us just part of the story. Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"pics/accuracy.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The document collection D:\n",
    "<img src=\"pics/accuracy2.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "         comp.graphics       0.87      0.97      0.92       389\n",
      "               sci.med       0.97      0.84      0.90       396\n",
      "soc.religion.christian       0.96      0.99      0.98       398\n",
      "\n",
      "           avg / total       0.93      0.93      0.93      1183\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# per-class breakdown\n",
    "from sklearn import metrics\n",
    "print(metrics.classification_report(y_true, y_predicted,\n",
    "     target_names=twenty_test.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Precision, Recall and F1:\n",
    "\n",
    "* **precision**: out of those predicted as a label, how many were correct\n",
    "* **recall**: how many instances, out of all instances of a specific label, did the classifier predict correctly\n",
    "* **f1-score**: harmonic mean of precision and recall (f1 has beta=1, i.e., both precision and recall are equally important)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"pics/precision_recall.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "From Wikipedia: <img src=\"https://upload.wikimedia.org/wikipedia/commons/2/26/Precisionrecall.svg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"pics/fscore.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* pay attention when using accuracy if the categories are very skewed (one class that is much more frequent than others)\n",
    "* in such a case, how can you achieve high accuracy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Evaluation - two data scenarios\n",
    "\n",
    "* Having a pre-split **train**/**dev**/**test** data: \n",
    "    * Build system using training data, use dev (development) data to find the right features, parameters etc.\n",
    "    * Only at the very end evaluate your system on the final (held-out) test data\n",
    "    \n",
    "* **Cross-validation** / also called $k$-fold cross validation: split data into $k$ folds (parts), train a model on $k-1$ parts, evaluate on the last part; do this $k$ times and report final average (and std dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Summary:\n",
    "\n",
    "* We have seen how to build a classifier with `sklearn` using word unigrams BOW features (exercise: examine the vectorizers of `sklearn`, try to use `DictVectorizer`)\n",
    "* Evaluation is important (how to measure performance - accuracy, precision, recall, f1 score; as well as how the evaluation is setup/evaluation scenario)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Building a Pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "In order to make the steps from input data to vectorizer to training a model easier, `sklearn` provides a `Pipeline`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "0.906790945406\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "vectorizer = CountVectorizer(binary=True)\n",
    "#vectorizer = TfidfVectorizer()\n",
    "clf = LogisticRegression()\n",
    "classifier = Pipeline( [('vec', vectorizer),\n",
    "                        ('clf', clf)] )\n",
    "print(clf)\n",
    "classifier.fit(twenty_train.data, twenty_train.target)\n",
    "y_predicted = classifier.predict(twenty_test.data)\n",
    "print(accuracy_score(twenty_test.target, y_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "# References\n",
    "\n",
    "* http://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html\n",
    "* http://scikit-learn.org/stable/modules/feature_extraction.html"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
