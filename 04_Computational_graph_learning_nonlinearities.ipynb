{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Neural Networks - Graph view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "After this lecture you should:\n",
    "* understand why we need non-linearities\n",
    "* understand the computational graph abstraction and how it relates to backprob\n",
    "* know how to define a feedforward neural network in `DyNet`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Recap: Feed-forward Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We have seen how a neural network can be formalized, both algebraically and graphically. we can think of a feed-forward NN as a function $NN(\\mathbf{x})$: $$y= NN(\\mathbf{x}) $$\n",
    "\n",
    "with:\n",
    "input: $\\mathbf{x}$ (vector with $d_{in}$ dimensions)\n",
    "\n",
    "output: $\\mathbf{y}$ (output with $d_{out}$ classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Recall our network: <img src=\"pics/nn.png\"> \n",
    "$$NN_{MLP1}(\\mathbf{x})=g(\\mathbf{xW^1+b^1})\\mathbf{W^2}+\\mathbf{b^2}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Recall that you can also see it as vector-matrix operations:\n",
    "\n",
    "* In the first layer, the input of 4 dimensions ($x_{1x4}$) is transformed into a vector of 5 dimensions:\n",
    "\n",
    "$$\\textbf{x}_{1x4} \\cdot \\textbf{W}^1_{4x5} \\rightarrow \\textbf{v}_{1x5}$$\n",
    "\n",
    "to which the bias vector is added, and the whole is send through the activation function to calculate the hidden layer values:\n",
    "\n",
    "$$\\textbf{v}_{1x5} + \\textbf{b}_{1x5} \\rightarrow \\mbox{apply } g \\rightarrow \\textbf{h}_{1x5}$$\n",
    "\n",
    "and so forth until the end:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "$$\\mathbf{h1}=g(\\mathbf{xW^1+b^1})$$\n",
    "$$NN_{MLP1}(\\mathbf{x})=\\mathbf{h1}\\mathbf{W^2}+\\mathbf{b^2}$$\n",
    "\n",
    "Which size does $\\mathbf{W^2}$ and $\\mathbf{b^2}$ have?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "answer: W2 = 5x1 b2 = 1x1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "What we just did (calculate the output from the input) is also called the **forward pass** in a neural network.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.43393611  0.5452903  -0.166863    0.69230561]\n",
      "[[ 0.5]]\n",
      "the network has no weights yet..\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "## sigmoid activation function\n",
    "f = lambda x: 1.0/(1.0 + np.exp(-x)) # activation function (here we use sigmoid)\n",
    "\n",
    "# define input\n",
    "x = np.random.randn(4) # random input vector of three numbers (1x4) \n",
    "print(x)\n",
    "\n",
    "# model parameters\n",
    "W1 = np.zeros((4,5))   # Weights W1 (3x5)\n",
    "W2 = np.zeros((5,1))   # Weights (4x4)\n",
    "b1 = np.zeros((1,5))\n",
    "b2 = np.zeros((1,1))\n",
    "\n",
    "# forward-pass of the feedforward neural network:\n",
    "h1=f(np.dot(x,W1)+b1) # calculate the activations of the first hidden layer (1x5) - linear transformation followed by non-linearity!\n",
    "out=f(np.dot(h1,W2)+b2) # calculate output (1x1)\n",
    "print(out)\n",
    "print(\"the network has no weights yet..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "All $\\mathbf{W}$ and $\\mathbf{b}$ are the **parameters** (or **weights**) of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "### Where do the weights come frome?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "### Intuition\n",
    "We want to adjust the weights so that *a small change in the output should have a small effect in the output*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "In case of the simples model, a simple perceptron, a small change might often have a large effect. Remember, the decision function for the perceptron is a threshold, this can be seen as a **step function**: <img src=\"https://upload.wikimedia.org/wikipedia/commons/a/ac/HardLimitFunction.png\" width=300> \n",
    "\n",
    "It is 0 for everything below 0 and 1 for positive outputs. If you are already close to the threshold, a small change might have a large effect.\n",
    "<img src=\"http://neuralnetworksanddeeplearning.com/images/tikz8.png\">\n",
    "\n",
    "For another reason that we will see later, we will not use simple thresholding, i.e., a **step function**, but rather a smoother function like the **sigmoid** function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"https://what-if.xkcd.com/imgs/whatif-logo.png\">\n",
    "\n",
    "### What if all the non-linearities in an NN suddenly vanished?\n",
    "\n",
    "<small>(CREDITS: The following slide has been taken from AJ and ZA's tutorial):</small>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "For now, lets simply ignore the bias term to simplfiy our notation. \n",
    "\n",
    "A neural network with an input layer, a middle layer, and an output layer computes the following:\n",
    "\n",
    "$$\\mathbf{y} = g(W^{(0)}g(W^{(1)}g(W^{(0)}\\mathbf{x})))$$\n",
    "\n",
    "$g$ is a non-linearity, which could be different for each layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "If we change $g$ to a linear function (e.g. a scaling factor), it can simply be multiplied into the weights matrices. Below we assume that $g = 1$, which allows us to simplify the expression:\n",
    "\n",
    "$$\\mathbf{y} = (W^{(0)}(W^{(1)}(W^{(0)}\\mathbf{x})))$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Since matrix multiplication is associative:\n",
    "\n",
    "$$A(BC) = (AB)C,$$\n",
    "\n",
    "we can get rid of the brackets altogether:\n",
    "\n",
    "$$\\mathbf{y} = W^{(0)}W^{(1)}W^{(0)}\\mathbf{x}.$$\n",
    "\n",
    "The series of linear transformations can be summarized in a single transformation matrix :\n",
    "\n",
    "$$T = W^{(0)}W^{(1)}W^{(0)}.$$\n",
    "\n",
    "And so the prediction of the neural network becomes:\n",
    "\n",
    "$$\\mathbf{y} = T\\mathbf{x}.$$\n",
    "\n",
    "The effective number of parameters in the now non non-linear neural network is $|\\mathbf{y}| \\times |\\mathbf{x}|$, which is precisely the same as a standard linear model.\n",
    "\n",
    "i.e., **the non-linearities are crucial**!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Commonly-used activation functions\n",
    "Tanh: <img src=\"http://cs231n.github.io/assets/nn1/tanh.jpeg\">\n",
    "Sigmoid: <img src=\"http://cs231n.github.io/assets/nn1/sigmoid.jpeg\">\n",
    "ReLu: <img src=\"http://cs231n.github.io/assets/nn1/relu.jpeg\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### So, where do the weights come from?\n",
    "\n",
    "It's an **optimization** problem. We want to find the weights that \"work best\". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"pics/mountains_at_home.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Training a Neural Network: Ingredients\n",
    "\n",
    "* we need to **define what \"works best\" means**\n",
    "* we need **a way to change the model (parameters)** to get closer to a good model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Defining what works best ~ how close we are: Loss\n",
    "\n",
    "Measures how 'far off' we are from true solution:\n",
    "\n",
    "$$L(\\mathbf{\\hat{y}},\\mathbf{y})$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### How to get closer to a good model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Strategy 1:** random guessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Strategy 2:** start with some random initial parameters (weights), and randomly adjust them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Strategy 3:** follow the gradient: analytical method to find the best direction along which we should change our weight vector: **gradient descent**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/6/6d/Error_surface_of_a_linear_neuron_with_two_input_weights.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### To sum up: Ingredients for training a Neural Network\n",
    "\n",
    "* we need to define what \"works best\" means \n",
    "    $\\rightarrow$ minimize some **loss**\n",
    "* we need a way to change the parameters to get closer to a good model\n",
    "    $\\rightarrow$ **minimize loss using a gradient-based method: gradient descent**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Intuitively, training a neural networks involves the following steps:\n",
    "\n",
    "* compute the gradient of the loss function with respect to the parameters\n",
    "* move the parameters in the negative direction of the gradient to decrease the loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Skeleton of gradient descent:\n",
    "    \n",
    "**Input**: training set, loss function $L$\n",
    "\n",
    "Repeat for number of iterations (**epochs**): \n",
    " \n",
    "* compute loss on data: $L(X,Y)$\n",
    "* compute gradients: $\\mathbf{g} = L(X,Y)$ with respect to $w$\n",
    "* move parameters in negative direction of the gradient: $w = w - \\eta \\mathbf{g}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Loss functions\n",
    "\n",
    "For **multi-class** classification the **cross-entropy** is a commonly used loss function: \n",
    "\n",
    "$$L_{crossentropy}(\\mathbf{\\hat{y}},\\mathbf{y})= - log(\\hat{y}_i)$$\n",
    "\n",
    "In `DyNet` this is implemented as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function _dynet.pickneglogsoftmax>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dynet as dy\n",
    "dy.pickneglogsoftmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "For **binary** classification you can use the binary log loss. In DyNet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function _dynet.binary_log_loss>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dy.binary_log_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Computational Graph & DyNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We want to get an intuitive understanding of the **backpropagation** algorithm. Backprob is a way of computing **gradients** of expressions through applying the **chain rule**. But before we get into details of gradients etc, lets introduce the **computational graph abstraction**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Imagine you have a task where you classify an input of 150 dimensions into 17 classes (let us use the illustration from before, except for assuming that you have 150 input nodes, not 4 as illustrated). And let us use as simple feedforward neural network with one hidden layer defined as follows:\n",
    "\n",
    "$$NN_{MLP1}(\\mathbf{x})=g(\\mathbf{xW^1+b^1})\\mathbf{W^2}+\\mathbf{b^2}$$\n",
    "\n",
    "<img src=\"pics/nn.png\" width=300> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## How can we represent this in DyNet?\n",
    "\n",
    "We need to define a model and all \"pieces\" of the model (its parameters - which need to be learned)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "model = dy.Model()\n",
    "\n",
    "input_size = 150\n",
    "hidden_size = 100\n",
    "num_labels = 17\n",
    "\n",
    "W1 = model.add_parameters((input_size, hidden_size)) # weights 1\n",
    "b1 = model.add_parameters((hidden_size))             # bias \n",
    "\n",
    "W2 = model.add_parameters((hidden_size, num_labels)) # weights 2\n",
    "b2 = model.add_parameters((num_labels))             # bias\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "So far so good. But these are just the components. We still need to define the full model by connecting the pieces:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def score_input(x):\n",
    "    dy.renew_cg()\n",
    "    \n",
    "    # everything in DyNet needs to be a DyNet expression (e.g., inputVector, parameter, etc)\n",
    "    input_vec = dy.inputVector(x)\n",
    "    a_1 = x * dy.parameter(W1) + b1 \n",
    "    h = dy.tanh(a1)\n",
    "    a_2 = h * dy.parameter(W2) + b2\n",
    "    return dy.softmax(a_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "We can represent our neural network as **computational graph**: nodes are operations, gray boxes are parameters.\n",
    "\n",
    "**IMPORTANT**: Explain the code snippet above to your neighbor, by relating it to the computational graph shown below. \n",
    "\n",
    "<img src=\"pics/yg-compgraph1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Why computational graph?\n",
    "\n",
    "It helps us to understand the flow of parameters in the model. \n",
    "\n",
    "- for the forward pass (to calculate the output, e.g. softmax or sigmoid/logistic output)\n",
    "- but also for the backward pass, i.e., the calculation of the gradients to update the parameters\n",
    "\n",
    "\n",
    "#### Backward step\n",
    "\n",
    "What do we need to compute? the gradient of the loss function with respect to the parameters.\n",
    "\n",
    "**What's a gradient?**: A vector of partial derivatives. \n",
    "\n",
    "The following slides will illustrate this. In DyNet we have automatic gradient computation, thus we get it for free!\n",
    "\n",
    "The follwing piece of code does the gradient computation and update of the paramters for us. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "## assuming we have defined the loss and a specific trainer\n",
    "loss.backward()\n",
    "trainer.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise time!\n",
    "\n",
    "A neural network is a big network of many 'neurons'. A single neuron could be a perceptron, *or*, a model that you already saw yesterday, a logistic regression node! (with sigmoid/logistic output)\n",
    "\n",
    "Now take the starter code in `exercise2.tar.gz` and answer the questions. It implements a logistic regression classifier (for binary classification) in `DyNet`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### More details (optional)\n",
    "\n",
    "Recall: the **derivative** \n",
    "\n",
    "A derivative gives us a linear approximation of the function at a specific point. Intuitively, the derivative indicates the rate of change of a function $f$ with respect to a variable $x$ (surrounding the region around point $h$):\n",
    "\n",
    "    \n",
    "<img src=\"http://www.intuitive-calculus.com/images/what-is-a-derivative-4.gif\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Gradient\n",
    "\n",
    "We are interested in finding the gradient, i.e., all partial derivatives, since our functions are not just functions of single parameters, but of a lot of parameters. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Example: gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Lets take a simple example of a function: $$f(x) = (x * y)$$ (or simply): $$f(x)=xy$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We want to calculate the gradient, the vector of partial derivatives (how much does the function change wrt the parameters x and y): $$\\nabla f = [\\frac{\\partial f}{\\partial x}, \\frac{\\partial f}{\\partial y}]$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The partial derivatives of this function are:\n",
    "\n",
    "$$f(x,y) = x y \\hspace{0.5in} \\rightarrow \\hspace{0.5in} \\frac{\\partial f}{\\partial x} = y \\hspace{0.5in} \\frac{\\partial f}{\\partial y} = x$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "## f(x) = x * y\n",
    "# lets take some numbers \n",
    "x = 4\n",
    "y = -3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-12\n"
     ]
    }
   ],
   "source": [
    "## forward pass (function application)\n",
    "f = x * y\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "## the derivative of each variable tells us the sensitivity of the whole expression on its value. \n",
    "## for instance, take the partial derivative of f wrt y:\n",
    "df_dy = x  # it's simply y \n",
    "print(x) # this means if we increase the y by a tiny amount, the whole function would increase by this amount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3\n"
     ]
    }
   ],
   "source": [
    "## similarly, the partial derivative of f w.r.t. x is:\n",
    "df_dx = y\n",
    "print(y)  # changing x by some small amount would make the whole expression decrease (negative sign)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**the derivative on each variable tells you the sensitivity of the whole expression on its value**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example 2: computational graph - compound expression\n",
    "\n",
    "(Thanks to lecture notes by Fei-Fei, Karphaty and Johnson, cf: http://cs231n.github.io/optimization-2/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Lets take the function: $$f(x) = (x + y) + z$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Lets represent it as computational graph (green: forward pass values):\n",
    "<img src=\"pics/k1.png\"> Slide by Fei-Fei, Karpathy and Johnson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"pics/k2.png\"> Slide by Fei-Fei, Karpathy and Johnson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"pics/k3.png\"> Slide by Fei-Fei, Karpathy and Johnson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"pics/k4.png\"> Slide by Fei-Fei, Karpathy and Johnson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"pics/k5.png\"> Slide by Fei-Fei, Karpathy and Johnson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"pics/k6.png\"> Slide by Fei-Fei, Karpathy and Johnson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"pics/k7.png\"> Slide by Fei-Fei, Karpathy and Johnson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"pics/k8.png\"> Slide by Fei-Fei, Karpathy and Johnson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"pics/k9.png\"> Slide by Fei-Fei, Karpathy and Johnson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"pics/k10.png\"> Slide by Fei-Fei, Karpathy and Johnson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"pics/k11.png\"> Slide by Fei-Fei, Karpathy and Johnson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"pics/k13.png\"> Slide by Fei-Fei, Karpathy and Johnson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"pics/graph.png\"> Slide by Fei-Fei, Karpathy and Johnson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Using the chain rule\n",
    "\n",
    "* we can compute the gradients of the loss along the backward path in our computational graph\n",
    "* once we know the gradients: we know how much we should change our parameters (in negative direction of gradients, as we want to minimize the loss): $w \\pm -\\eta \\mathbf{g}$\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "###### Gradient descent\n",
    "\n",
    "Repeat for number of iterations (**epochs**): \n",
    "* compute loss on data: $L(X,Y)$\n",
    "* compute gradients: $\\mathbf{g} = L(X,Y)$ with respect to $w$\n",
    "* move parameters in opposite direction of gradient: $w \\pm -\\eta \\mathbf{g}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### In practice:\n",
    "\n",
    "* **stochastic gradient descent** (online learning)\n",
    "* **mini-batches** (use a small subset of training instances) (minibatch size)\n",
    "* **further hyperparameters**: learning rate $\\eta$ (how big a step we take), number of epochs (how often we go over training data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## References\n",
    "\n",
    "* Yoav Goldberg's primer chapter 6: [A Primer on Neural Network Models for Natural Language Processing](http://arxiv.org/abs/1510.00726)\n",
    "* Fei-Fei, Karpathy and Johnson's lecture notes: http://cs231n.github.io/optimization-2/"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
