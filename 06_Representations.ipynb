{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Neural Networks - Representations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "After this lecture you should:\n",
    "* know why we go from n-hot vectors (sparse) to embedding inputs (dense inputs)\n",
    "* understand the basics of RNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Recap: Feed-forward Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "$$NN_{MLP1}(\\mathbf{x})=g(\\mathbf{xW^1+b^1})\\mathbf{W^2}+\\mathbf{b^2}$$\n",
    "\n",
    "<img src=\"pics/yg-compgraph1.png\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "However, what is the input $\\textbf{x}$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Recap: Features so far\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Before we go further, lets make a detour and recap: How did we represent a training instance so far?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "For instance, recall our example from day 1: training a Logistic Regression classifier for sentiment classification. \n",
    "\n",
    "* Describe in words: what were the features we used? I.e., how did we represent a training instance $\\textbf{x}$?\n",
    "* How can you now describe the entire sentiment training data set as a matrix $X$, i.e.,  what are the rows and columns of $X$? $$ X = \\{\\mathbf{x_1}, ... , \\mathbf{x_n}\\} $$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "So far we used **sparse** inputs (n-hot encodings)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "After this lecture you should:\n",
    "* know about **distributional similarity** (embeddings: --traditional:LSA--, --neural:word2vec--)\n",
    "* understand the difference between **discrete** (one-hot) and **dense** feature representations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Representations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**discrete representation**\n",
    "\n",
    "$$\\mathbf{x}_{cat} = [0,0,0,0,0,0,1] $$\n",
    "$$\\mathbf{x}_{dog} = [0,0,0,0,1,0,0] $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**similarity** on discrete representations? $$\\mathbf{x}_{cat} \\wedge \\mathbf{x}_{dog} = 0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Probably the biggest jump when moving from traditional linear models with sparse inputs to deep neural networks is to stop representing each feature as a unique dimension, but instead represent them as **dense vectors** (Goldberg, 2015)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Instead of using discrete representations, we will **embed** words into a high-dimensional feature space and represent each word by a lower-dimensional dense *vector* (aka. *embedding*):\n",
    "<img src=\"http://ben.bolte.cc/resources/attention_rnn/word_vectors.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Representing words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center>**\"You shall know a word by the company it keeps\"** (Firth, J. R. 1957:11)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"pics/flÃ¸debolle.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### \"The company it keeps\": word co-occurence matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We can represent the \"company\" of a word in terms of a word co-occurence matrix. On the rows we have the words, on the columns their context.\n",
    "\n",
    "**Contexts** can be of different types, for example:\n",
    "* entire documents\n",
    "* paragraphs\n",
    "* a window around the word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Example corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "corpus = [\"She enjoys Groningen .\", \n",
    "          \"I like Cockatoos .\", \n",
    "          \"She likes good food .\", \n",
    "          \"I like Groningen .\",\n",
    "          \"good times\"\n",
    "         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'She', 'Cockatoos', 'food', 'I', 'like', '.', 'good', 'times', 'likes', 'Groningen', 'enjoys'}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "vocab = set(np.concatenate([s.split() for s in corpus],0))\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Co-occurence matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab size:  11\n",
      "[[ 1.  1.  1.  1.  0.]\n",
      " [ 0.  1.  0.  0.  0.]\n",
      " [ 1.  0.  0.  1.  0.]\n",
      " [ 0.  1.  0.  1.  0.]\n",
      " [ 1.  0.  1.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  1.  0.  1.]\n",
      " [ 0.  1.  0.  1.  0.]\n",
      " [ 0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.]]\n"
     ]
    }
   ],
   "source": [
    "# lets build a co-occurence matrix \n",
    "# rows: indices of words\n",
    "# columns: each column is a document, register whether the word appeared in the context\n",
    "## (in practice: many more context, different weighting schemes etc..)\n",
    "w2i = {w: i for i,w in enumerate(sorted(vocab))}\n",
    "i2w = {i: w for i,w in enumerate(w2i)}\n",
    "\n",
    "coocurrence_matrix = np.zeros((len(vocab),len(corpus)))\n",
    "for col_idx, sentence in enumerate(corpus):\n",
    "    sentence = sentence.split()\n",
    "    for word in sentence:\n",
    "        word_idx = w2i[word]\n",
    "        coocurrence_matrix[(word_idx,col_idx)] +=1\n",
    "\n",
    "print(\"vocab size: \", len(w2i))\n",
    "print(coocurrence_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with row info:\n",
      "0\t.\t[ 1.  1.  1.  1.  0.]\n",
      "1\tCockatoos\t[ 0.  1.  0.  0.  0.]\n",
      "2\tGroningen\t[ 1.  0.  0.  1.  0.]\n",
      "3\tI\t[ 0.  1.  0.  1.  0.]\n",
      "4\tShe\t[ 1.  0.  1.  0.  0.]\n",
      "5\tenjoys\t[ 1.  0.  0.  0.  0.]\n",
      "6\tfood\t[ 0.  0.  1.  0.  0.]\n",
      "7\tgood\t[ 0.  0.  1.  0.  1.]\n",
      "8\tlike\t[ 0.  1.  0.  1.  0.]\n",
      "9\tlikes\t[ 0.  0.  1.  0.  0.]\n",
      "10\ttimes\t[ 0.  0.  0.  0.  1.]\n"
     ]
    }
   ],
   "source": [
    "print(\"with row info:\")\n",
    "for i, row in enumerate(coocurrence_matrix):\n",
    "    print(\"{}\\t{}\\t{}\".format(i, i2w[i], row))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Co-occurence matrix\n",
    "\n",
    "* **dimensionality**: number of words $|V|$ (size of vocabulary) times number of documents (typically number of documents is huge)\n",
    "* we want to **reduce** its dimensionality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### LSA - Latent Semantic Analysis (Singular Value Decomposition - SVD)\n",
    "\n",
    "Approximate a matrix $\\mathbf{C}$ through a decomposition into three submatrices (**of smaller dimensionality**):\n",
    "\n",
    "$$\\mathbf{C} \\approx \\mathbf{U \\sum V^T}$$\n",
    "\n",
    "<img src=\"https://simonpaarlberg.com/posts/2012-06-28-latent-semantic-analyses/box2.png\">\n",
    "\n",
    "NB. $=$ should be $\\approx$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.extmath import randomized_svd\n",
    "\n",
    "# reduce space to, say, 2 dimensions (for simplicity here)\n",
    "U, Sigma, VT = randomized_svd(coocurrence_matrix, \n",
    "                              n_components=2)\n",
    "print(U.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Visualizing the vector space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'She', 'Cockatoos', 'food', 'I', 'like', '.', 'good', 'times', 'likes', 'Groningen', 'enjoys'}\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nHxEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11ca1a518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of U: (11, 2)\n",
      "vector for 'likes': [ 0.15663919  0.32849558]\n",
      "vector for 'enjoys': [ 0.15680191  0.09115486]\n",
      "vector for 'good': [ 0.17807516  0.45032677]\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "print(vocab)\n",
    "for word in vocab:\n",
    "    i=w2i[word]\n",
    "    plt.text(U[i,0]+0.01,U[i,1], word)\n",
    "    plt.plot(U[i,0],U[i,1], 'o')\n",
    "plt.show()\n",
    "print(\"size of U:\", U.shape)\n",
    "print(\"vector for 'likes':\", U[w2i[\"likes\"]])\n",
    "print(\"vector for 'enjoys':\", U[w2i[\"enjoys\"]])\n",
    "print(\"vector for 'good':\", U[w2i[\"good\"]])\n",
    "#for w in vocab:\n",
    "#    print(\"vector for '{}': {}\".format(w, U[w2i[w]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Similarity\n",
    "\n",
    "**cosine** similarity \n",
    "\n",
    "<img src=\"https://simonpaarlberg.com/posts/2012-06-28-latent-semantic-analyses/eq1.png\">\n",
    "<img src=\"https://simonpaarlberg.com/posts/2012-06-28-latent-semantic-analyses/vector_example2.png\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Exercise**: Calculate the cosine distance between the words *good* and *enjoys* as well as *enjoys* and *likes*. (Hint: you can use the *cosine* **distance** function from *scipy.spatial.distance*, notice it is 1 minus cosine similarity). What is the distance between a word and itself?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosine distances:\n",
      "good<>enjoys:     0.21\n",
      "enjoys<>likes: 0.17\n",
      "good<>good: -0.00\n"
     ]
    }
   ],
   "source": [
    "## solution:\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "v_likes = U[w2i[\"likes\"]]\n",
    "v_enjoys = U[w2i[\"enjoys\"]]\n",
    "v_good = U[w2i[\"good\"]]\n",
    "\n",
    "print(\"cosine distances:\")\n",
    "print(\"good<>enjoys:     {0:.2f}\".format(cosine(v_good, v_enjoys)))\n",
    "print(\"enjoys<>likes: {0:.2f}\".format(cosine(v_enjoys, v_likes)))\n",
    "print(\"good<>good: {0:.2f}\".format(cosine(v_good, v_good)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Deep learning approach: Directly learning word vectors (embeddings)\n",
    "\n",
    "* SVD: computation cost scales quadratically with size of co-occurence matrix; difficult to integrate new words\n",
    "* **Idea**: directly learn word vectors (word2vec)\n",
    "    * NLP (almost) from Scratch (Collobert & Weston, 2008)\n",
    "    * word2vec (Mikolov et al, 2013)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Main idea of word2vec\n",
    "\n",
    "* instead of capturing co-occurence statistics of words\n",
    "* **predict context** (surrounding words of every word); in particular, predict words in a window of length $m$ around current word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$o$ is the outside word (context), $c$ is the current center word; \n",
    "\n",
    "Maximize the probability of a word in the context ($o$) given the current word $c$:\n",
    "\n",
    "$$p(o|c) = \\frac{exp(u_o^T v_c)}{\\sum_{w=1}^W exp(u_w^T v_c)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"http://www.gabormelli.com/RKB/images/a/a6/skip-gram_NNLM_architecture.150216.jpg\">\n",
    "\n",
    "At the end you can read off the embedding vector from the Embedding layer! voila!\n",
    "\n",
    "NB. denominator $\\sum$ over all words! In practice, *negative sampling* is used (randomly choose a word which is not in context as a negative sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In deep learning we represent words as vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**a) sparse representation vs b) dense representation**  (Figure 1 in Yoav Goldberg's primer)\n",
    "<img src=\"pics/sparsevsdense.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Traditional vs deep learning approach to feature extraction (representations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The common pipeline of extracting features **for an NLP model with a Neural Network** then becomes:\n",
    "\n",
    "* extract a set of core linguistic features $f_1,..f_n$\n",
    "* define a **vector** for **each feature** (lookup Embedding table)\n",
    "* **combine** vectors of features to get the vector representation for the **instance** $\\mathbf{x}$ (**dense representation**)\n",
    "* use $\\mathbf{x}$ as representation for an instance, train the model\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Lets compare this to our traditional approach - the common pipeline of extracting features for an NLP model is:\n",
    "\n",
    "* extract a set of core linguistic features $f_1,..f_n$\n",
    "* define a vector whose length is the total number of features with a 1 at position k if the k-th feature is active; this feature vector represents the **instance** $\\mathbf{x}$  (**sparse representation**, n-hot encoding)\n",
    "* use $\\mathbf{x}$ as representation for an instance, train the model\n",
    "\n",
    "Now it should be clear why it is called sparse vs dense feature representation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### How do you combine different feature vector representations?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In an NLP application, $\\mathbf{x}$ is usually composed of various embedding vectors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Following the notation in Goldberg (2015), chapter 4, lets use the function $c(\\cdot)$ as **feature combiner** that creates our input embeddings layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "A common choice for $c$ is **concatenation**:\n",
    "\n",
    "$\\mathbf{x} = c(f_1, f_2, f_3) = [v(f_1); v(f_2); v(f_3)] $\n",
    "\n",
    "This is what happens if we use **Flatten** in Keras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Alternatively, $c$ could be the **sum of the embeddings vector**:\n",
    "\n",
    "$\\mathbf{x} = c(f_1, f_2, f3) = [v(f_1)+v(f_2)+v(f_3)] $\n",
    "\n",
    "or the **mean**:\n",
    "\n",
    "$\\mathbf{x} = c(f_1, f_2, f3) = [mean(v(f_1),v(f_2),v(f_3))] $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In many papers $v$ is often referred to as the embeddings layer or lookup layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Our example from before with explicit input representation\n",
    "\n",
    "For instance, let us explicitly state the input representation. Suppose we use the concatentation operator, then our network above becomes:\n",
    "\n",
    "<img src=\"pics/nn.png\" width=300> \n",
    "\n",
    "since: \n",
    "$\\mathbf{x} = c(f_1, f_2, f3) = [v(f_1); v(f_2); v(f_3)] $\n",
    "\n",
    "then: \n",
    "\n",
    "$NN_{MLP1}(\\mathbf{x})=g(\\mathbf{[v(f_1); v(f_2); v(f_3)]W^1+b^1})\\mathbf{W^2}+\\mathbf{b^2}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "As computational graph:\n",
    "<img src=\"pics/yg-compgraph2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The values of the *embedding vectors* (values of the vectors in Fig 1 b)) are treated as model parameters and trained together with the other parameters of the model (weights)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Unrolled (graph with concrete input, expected output, and loss node, Goldberg Figure 3 c):\n",
    "<img src=\"pics/yg-compgraph3.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Florida', 0.9196957945823669),\n",
       " ('Arlington', 0.9070820808410645),\n",
       " ('California', 0.8937997817993164),\n",
       " ('Buffalo', 0.8546850085258484),\n",
       " ('Canada', 0.8518165349960327),\n",
       " ('Japan', 0.8483419418334961),\n",
       " ('Europe', 0.8347345590591431),\n",
       " ('Houston', 0.8322141170501709),\n",
       " ('Virginia', 0.8314700126647949),\n",
       " ('France', 0.8283012509346008)]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# once we have read off the embeddings after training the animacy classifier, and \n",
    "# stored them in file 'vectors.txt' we load it for inspection\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "w2v = KeyedVectors.load_word2vec_format('./vectors.txt', binary=False)\n",
    "w2v.most_similar(positive=['Texas'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('elect', 0.851630449295044),\n",
       " ('word', 0.8355662822723389),\n",
       " ('letting', 0.8245967030525208),\n",
       " ('teach', 0.8199971914291382),\n",
       " ('swaying', 0.81275475025177),\n",
       " ('parks', 0.811647891998291),\n",
       " ('finally', 0.7990972995758057),\n",
       " ('wishes', 0.793840765953064),\n",
       " ('repainted', 0.7927937507629395),\n",
       " ('jus-', 0.787428617477417)]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.most_similar(positive=['send'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "These vectors are not traditional word vectors learned with word2vec (skipgrams), instead we read them off from our animacy classifier (they are not trained with the word2vec objective, but are a by-product from the classifier). Nevertheless this shows us that we can also get embeddings from a neural network with dense (embedding) inputs! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Word Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "So, in deep learning approaches to NLP words are represented as dense vectors. Where do these word vectors (embeddings) come from?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* **off-the-shelf embeddings**: you can also use trained, available embeddings (e.g. estimated with *word2vec*) and *initialize* the embedding layer of the network with your pretrained (unsupervised) word embeddings\n",
    "* **task-specific embeddings**: you could also train your embeddings from scratch with the data for your task. In this case, the vectors are typically **randomly initialized** (small numbers around 0) and *trained with the network*. At the end you can read them off the network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Remember, today we have seen tree ways to get embeddings:\n",
    "\n",
    "1. Traditional methods (also called 'count' methods): SVD on a co-occurence matrix (=LSA)\n",
    "2. Neural method #1 (also called 'predict' methods): word2vec (train on large unlabeled corpus)\n",
    "3. Neural method #2 (also a 'predict' method, but task-specific): train your embeddings on your supervised task, read them off at the end (typically less used as you will have less supervised training data, it's easier to get loads of unlabeled text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Inputs of different lengths\n",
    "\n",
    "In our animacy classification example we have one simplification: the input is always of the same size (namely, 5 words). \n",
    "\n",
    "However, in NLP we typically never have fixed size inputs, sentences are of different length. The neural network however needs inputs of fixed size. So how to deal with it?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* create an input of fixed size, like using the mean embedding vector\n",
    "* use a model that can deal with variable size inputs, like a recurrent neural network (depending on the deep learning toolkit you use, you might still need to *pad* sequences to a fixed length)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Karpathy's illustration of RNNs:\n",
    "<img src=\"http://benjaminbolte.com/resources/attention_rnn/karpathy_rnn.jpeg\">\n",
    "\n",
    "* From left to right: (1) Vanilla mode of processing without RNN, from fixed-sized input to fixed-sized output (e.g. image classification). (2) Sequence output (e.g. image captioning takes an image and outputs a sentence of words). (3) Sequence input (e.g. sentiment analysis where a given sentence is classified as expressing positive or negative sentiment). (4) Sequence input and sequence output (e.g. Machine Translation: an RNN reads a sentence in English and then outputs a sentence in French). (5) Synced sequence input and output (e.g. video classification where we wish to label each frame of the video). Notice that in every case are no pre-specified constraints on the lengths sequences because the recurrent transformation (green) is fixed and can be applied as many times as we like.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Important concepts: Prediction problems, non-neural baselines\n",
    "\n",
    "In NLP we typically deal with the following **prediction problems** - Given $x$, predict $y$:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "| Given $x$ | predict $y$  | Type of prediction problem | \n",
    "|------|------|\n",
    "|   a book review  | positive, negative | **classification** (binary) |\n",
    "|   a tweet  | language | **multi-class classification** (several choices) |\n",
    "|   a sentence  | its syntactic parse tree | **structured prediction** (millions of choices) |\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Sequence tagging is also a structured prediction problem.\n",
    "\n",
    "For a sequence of n words with just 2 possible tags, how many possible sequences?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "| Example task | Traditional classifier  | Type of prediction problem | \n",
    "|------|------|\n",
    "|   sentiment | Logistic regression, SVM | **classification** (binary) |\n",
    "|   language identification  | Logistic regression, SVM  | **multi-class classification** (several choices) |\n",
    "|   POS sequence  | HMM, structured perceptron, (window-based classifier) | **structured prediction** (millions of choices) |\n",
    "|   NER  | CRF, structured perceptron | **structured prediction** (millions of choices) |\n",
    "\n",
    "\n",
    "Remember: also think about the evaluation measure! \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### References\n",
    "\n",
    "* Yoav Goldberg's primer chapter 2 and 5: [A Primer on Neural Network Models for Natural Language Processing](http://arxiv.org/abs/1510.00726)\n",
    "* Simon Paarlberg's [blog on LSA](https://simonpaarlberg.com/post/latent-semantic-analyses/)\n",
    "* Richard Socher's [lecture 2](https://www.youtube.com/watch?v=xhHOL3TNyJs)\n",
    "* Graham Neubig's slides on the [structured perceptron](http://www.phontron.com/slides/nlp-programming-en-12-struct.pdf)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
