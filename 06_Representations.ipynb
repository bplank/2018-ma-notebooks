{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Neural Networks - Representations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "After this lecture you should:\n",
    "* know why we go from n-hot vectors (sparse) to embedding inputs (dense inputs)\n",
    "* understand the basics of RNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Recap: Feed-forward Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "$$NN_{MLP1}(\\mathbf{x})=g(\\mathbf{xW^1+b^1})\\mathbf{W^2}+\\mathbf{b^2}$$\n",
    "\n",
    "<img src=\"pics/yg-compgraph1.png\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "However, what is the input $\\textbf{x}$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Recap: Features so far\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Before we go further, lets make a detour and recap: How did we represent a training instance so far?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "For instance, recall our example from day 1: training a Logistic Regression classifier for sentiment classification. \n",
    "\n",
    "* Describe in words: what were the features we used? I.e., how did we represent a training instance $\\textbf{x}$?\n",
    "* How can you now describe the entire sentiment training data set as a matrix $X$, i.e.,  what are the rows and columns of $X$? $$ X = \\{\\mathbf{x_1}, ... , \\mathbf{x_n}\\} $$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "So far we used **sparse** inputs (n-hot encodings)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "After this lecture you should:\n",
    "* know about **distributional similarity** (embeddings: --traditional:LSA--, --neural:word2vec--)\n",
    "* understand the difference between **discrete** (one-hot) and **dense** feature representations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Representations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**discrete representation**\n",
    "\n",
    "$$\\mathbf{x}_{cat} = [0,0,0,0,0,0,1] $$\n",
    "$$\\mathbf{x}_{dog} = [0,0,0,0,1,0,0] $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**similarity** on discrete representations? $$\\mathbf{x}_{cat} \\wedge \\mathbf{x}_{dog} = 0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Probably the biggest jump when moving from traditional linear models with sparse inputs to deep neural networks is to stop representing each feature as a unique dimension, but instead represent them as **dense vectors** (Goldberg, 2015)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Instead of using discrete representations, we will **embed** words into a high-dimensional feature space and represent each word by a lower-dimensional dense *vector* (aka. *embedding*):\n",
    "<img src=\"http://ben.bolte.cc/resources/attention_rnn/word_vectors.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Representing words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center>**\"You shall know a word by the company it keeps\"** (Firth, J. R. 1957:11)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"pics/flÃ¸debolle.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### \"The company it keeps\": word co-occurence matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We can represent the \"company\" of a word in terms of a word co-occurence matrix. On the rows we have the words, on the columns their context.\n",
    "\n",
    "**Contexts** can be of different types, for example:\n",
    "* entire documents\n",
    "* paragraphs\n",
    "* a window around the word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Example corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "corpus = [\"She enjoys Malta .\", \n",
    "          \"I like Cockatoos .\", \n",
    "          \"She likes good food .\", \n",
    "          \"I like Malta .\",\n",
    "          \"good times\"\n",
    "         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'enjoys', 'Cockatoos', 'food', 'Malta', 'She', 'good', '.', 'like', 'I', 'likes', 'times'}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "vocab = set(np.concatenate([s.split() for s in corpus],0))\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Co-occurence matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab size:  11\n",
      "[[ 1.  1.  1.  1.  0.]\n",
      " [ 0.  1.  0.  0.  0.]\n",
      " [ 0.  1.  0.  1.  0.]\n",
      " [ 1.  0.  0.  1.  0.]\n",
      " [ 1.  0.  1.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  1.  0.  1.]\n",
      " [ 0.  1.  0.  1.  0.]\n",
      " [ 0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.]]\n"
     ]
    }
   ],
   "source": [
    "# lets build a co-occurence matrix \n",
    "# rows: indices of words\n",
    "# columns: each column is a document, register whether the word appeared in the context\n",
    "## (in practice: many more context, different weighting schemes etc..)\n",
    "w2i = {w: i for i,w in enumerate(sorted(vocab))}\n",
    "i2w = {i: w for i,w in enumerate(w2i)}\n",
    "\n",
    "coocurrence_matrix = np.zeros((len(vocab),len(corpus)))\n",
    "for col_idx, sentence in enumerate(corpus):\n",
    "    sentence = sentence.split()\n",
    "    for word in sentence:\n",
    "        word_idx = w2i[word]\n",
    "        coocurrence_matrix[(word_idx,col_idx)] +=1\n",
    "\n",
    "print(\"vocab size: \", len(w2i))\n",
    "print(coocurrence_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with row info:\n",
      "0\t.\t[ 1.  1.  1.  1.  0.]\n",
      "1\tCockatoos\t[ 0.  1.  0.  0.  0.]\n",
      "2\tI\t[ 0.  1.  0.  1.  0.]\n",
      "3\tMalta\t[ 1.  0.  0.  1.  0.]\n",
      "4\tShe\t[ 1.  0.  1.  0.  0.]\n",
      "5\tenjoys\t[ 1.  0.  0.  0.  0.]\n",
      "6\tfood\t[ 0.  0.  1.  0.  0.]\n",
      "7\tgood\t[ 0.  0.  1.  0.  1.]\n",
      "8\tlike\t[ 0.  1.  0.  1.  0.]\n",
      "9\tlikes\t[ 0.  0.  1.  0.  0.]\n",
      "10\ttimes\t[ 0.  0.  0.  0.  1.]\n"
     ]
    }
   ],
   "source": [
    "print(\"with row info:\")\n",
    "for i, row in enumerate(coocurrence_matrix):\n",
    "    print(\"{}\\t{}\\t{}\".format(i, i2w[i], row))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Co-occurence matrix\n",
    "\n",
    "* **dimensionality**: number of words $|V|$ (size of vocabulary) times number of documents (typically number of documents is huge)\n",
    "* we want to **reduce** its dimensionality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### LSA - Latent Semantic Analysis (Singular Value Decomposition - SVD)\n",
    "\n",
    "Approximate a matrix $\\mathbf{C}$ through a decomposition into three submatrices (**of smaller dimensionality**):\n",
    "\n",
    "$$\\mathbf{C} \\approx \\mathbf{U \\sum V^T}$$\n",
    "\n",
    "<img src=\"https://simonpaarlberg.com/posts/2012-06-28-latent-semantic-analyses/box2.png\">\n",
    "\n",
    "NB. $=$ should be $\\approx$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.extmath import randomized_svd\n",
    "\n",
    "# reduce space to, say, 2 dimensions (for simplicity here)\n",
    "U, Sigma, VT = randomized_svd(coocurrence_matrix, \n",
    "                              n_components=2)\n",
    "print(U.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Visualizing the vector space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'enjoys', 'Cockatoos', 'food', 'Malta', 'She', 'good', '.', 'like', 'I', 'likes', 'times'}\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xl4FeXd//H3lxAWCRAkoCKUKD8LhiyEhEVBkggKRJGyKFgVRHpRfIoWrVZqpaWWuvSxYqVaymMFbKlgEaooVgWhgIiQSIiyi1JlEcKSQMKWkPv3R2JMIJATzklOyHxe13WunLnPPTPfezTzYZacMeccIiLiPXWCXYCIiASHAkBExKMUACIiHqUAEBHxKAWAiIhHKQBERDxKASAi4lEKABERj1IAiIh4VN1gF3AuERERLjIyMthliIhcMNLT0/c751r40rdGB0BkZCRpaWnBLkNE5IJhZv/1ta9OAYmIeJQCQKrVjh07iI6ODnYZIoICQETEsxQAck6//e1vad++PT179uT222/nmWeeISMjg+7duxMbG8ugQYM4dOgQwFnb09PTiYuLIy4ujhdeeCGYwxGRUhQAclZr167l9ddfZ/369bzzzjslF+RHjBjB008/TWZmJjExMfzmN785Z/uoUaOYOnUq69evD9pYRORMCgAP27RiKdN/Moo/DB/A9J+MYtOKpWU+//DDDxk4cCANGjSgcePGDBgwgLy8PLKzs0lKSgJg5MiRLF++nJycnHLbs7Ozyc7OplevXgDcdddd1TtIETmrGn0bqFSdTSuW8t70P1Fw8gQAR/Zn8d70PwFw9XUpwSxNRKqJjgA8asWcV0p2/t8qOHmCFXNeKZnu0aMHCxcu5Pjx4+Tm5vLWW2/RqFEjmjVrxooVKwD429/+RlJSEk2bNi23PTw8nPDwcFauXAnA7Nmzq2mEIlIRHQF41JED+yts79KlC7fccguxsbFccsklxMTE0LRpU2bNmsXYsWM5evQoV155JTNmzAA4a/uMGTO45557MDNuvPHGqh9cgP3ud7/jH//4ByEhIdSpU4e//OUvDBs2jLS0NCIiIoJdnsh5s5r8UPjExESnvwSuGtN/Mooj+7POaG8c0YIxL8womc7NzSUsLIyjR4/Sq1cvpk+fTufOnauz1KD66KOPePDBB1m2bBn169dn//79nDx5kmuvvVYBIDWSmaU75xJ96atTQB513fAR1K1Xv0xb3Xr1uW74iDJtY8aMoVOnTnTu3JkhQ4Z4aucPsGfPHiIiIqhfv2hbRURE0KpVKwCmTp1K586diYmJYfPmzQDk5eVxzz330LVrV+Lj43njjTeCVrtIRXQE4GGbVixlxZxXOHJgP42bR3Dd8BG6AHya3NxcevbsydGjR+nTpw/Dhg0jKSmJyMhIfvazn3Hffffx4osv8sknn/DSSy/x6KOPEhUVxZ133kl2djZdu3Zl3bp1NGrUKNhDEY+ozBGArgF42NXXpXh+h7/142/46I3t5B48QdjF9blmYDu+3+3Sks/DwsJIT09nxYoVLF26lGHDhvHUU08BMHjwYAASEhKYP38+AO+99x5vvvkmzzzzDADHjx/nq6++4uqrr67mkYlUTAEgnrX1429YOnszBScLAcg9eIKls4tO5ZQOgZCQEJKTk0lOTiYmJoZZs2YBlJwWCgkJoaCgAADnHK+//jrt27evzqGInBddAxDP+uiN7SU7/28VnCzkoze2l0xv2bKFbdu2lUxnZGTQtm3bsy6zb9++TJ06lW9Pra5bty7AVYsEjgJAPCv34IkK23Nzcxk5ciRRUVHExsayceNGJk2adNZlTpw4kfz8fGJjY+nYsSMTJ04MdNkiAROQi8Bm1g/4IxACvOSce+os/boAHwHDnXPzKlquLgJLVZr16IflhkDYxfUZ+USPIFQk4r9qvQ3UzEKAF4D+QBRwu5lFnaXf08B7/q5TJBCuGdiOuvXK/grUrVeHawa2C1JFItUrEKeAugKfO+e+cM6dBOYAA8vpdx/wOrAvAOsU8dv3u11Kyh0dCLu46GJu2MX1SbmjQ5kLwCK1WSDuAroc+LrU9E6gW+kOZnY5MAhIAboEYJ0iAfH9bpdqhy+eVV0XgZ8DHnHOFVbU0czGmFmamaVlZZ35VQUiIhIYgTgC2AW0KTXdurittERgjpkBRACpZlbgnPvX6Qtzzk0HpkPRReAA1CciIuUIRACsBa4ysyso2vEPB35YuoNz7opv35vZTOCt8nb+IiJSffwOAOdcgZmNA96l6DbQl51zG8xsbPHn0/xdh4iIBF5AvgrCObcIWHRaW7k7fufc3YFYp4iI+Ed/CSwi4lEKABERj1IAiIh4lAJARMSjFAAeVL9+fa6++moGDRrE0KFDAZg5cybjxo2r1HIiIyPZv7/8h8uLSM2nB8J4UH5+Pu+//z6tW7cOdikiEkQKAI8ZO3Yszjn69+/PLbfcwtSpU4mMjCQvL48uXYq+pmnOnDn8z//8D5deeikNGzakWbNm5OTkUFBQQGhoKHl5eURGRrJ7926Sk5MJDQ1l+fLlNG7cOMijE5HK0Ckgj5k2bRpmxtKlS9m5cycNGjQgMzOTIUOGsHjxYhYsWMCDDz7ImDFj2LhxI+Hh4ezYsYO1a9fSqVMnvvzySzZs2EBWVhb5+fksW7aMFStW0LBhw2APTUQqSQFQCz2W+QFtFi/l0g/W0WbxUh7L/KDcfmvXriU8PByAqKgocnJyeOKJJ4iIiGDMmDEAfPrpp3z11VfExsYyZ84cQkJCyM3NZfDgwYSEhDB9+nSys7OpW1cHkyIXGgVALfNY5gf8NasR+SHNwIz8kGb8NavRWUOgtLp165Kbm8uJE989JauwsJCWLVuycuVK2rdvz6pVqwgLC2PChAk0atSI48eP06NHDzZv3lyVwxKRKqAAqGVm7TNcnfpl2lyd+szaZ2f07dq1Kzk5OQBs3ryZsLAwFixYQFZWFlOmTAEgLi4O5xxNmjShV69e/OEPfwDg5Zdf5vDhw9x///106dJFASByAdJxey2TXyfc5/bx48czf/58YmNjycvLo3fv3nTo0IH58+czYMAA3nvvPcLCwoiOjiY2NpYTJ06Ql5fHsmXLAAgNDSUpKYnY2Fj69+9flcMSkSqgAKhlQguzi07/lNP+rcLCoufyREREcPjw4TP6Jicnc+TIkaorUkRqBJ0CqmVGtnRY4YkybVZ4gpEt9WwdESlLAVDLTI69ntEt8gg9dQicI/TUIUa3yGNy7PXBLk1EahidAqqFJsdez+RgFyEiNZ6OAEREPEoBICLiUQoAERGPUgCIiHiUAkBExKMUACIiHqUAEBHxKAWAiIhHKQBERDxKASAi4lEKABERj1IAiIh4lAJARMSjFAAiIh6lABAR8SgFgIiIRykAREQ8SgEgIuJRCgAREY9SAIiIeJQCQETEoxQAIiIeFZAAMLN+ZrbFzD43swnlfH6HmWWa2admtsrM4gKxXhEROX9+B4CZhQAvAP2BKOB2M4s6rduXQJJzLgb4LTDd3/WKiIh/AnEE0BX43Dn3hXPuJDAHGFi6g3NulXPuUPHkaqB1ANYrIiJ+CEQAXA58XWp6Z3Hb2YwG3jnbh2Y2xszSzCwtKysrAOWJiEh5qvUisJmlUBQAj5ytj3NuunMu0TmX2KJFi+orTkTEY+oGYBm7gDalplsXt5VhZrHAS0B/59yBAKxXRET8EIgjgLXAVWZ2hZnVA4YDb5buYGbfA+YDdznntgZgnSIi4ie/jwCccwVmNg54FwgBXnbObTCzscWfTwN+BTQHXjQzgALnXKK/6xYRkfNnzrlg13BWiYmJLi0tLdhliIhcMMws3dd/YOsvgUVEPEoBICLiUQoAERGPUgCIiHiUAkBExKM8FQDZ2dm8+OKLAOzevZuhQ4cGuSIRkeDxbAC0atWKefPmBbkiEZHg8VQATJgwge3bt9OpUyduvfVWoqOjAZg5cyY/+MEPuOGGG4iMjORPf/oTzz77LPHx8XTv3p2DBw8CsH37dvr160dCQgLXXXcdmzdvBuCf//wn0dHRxMXF0atXr6CNT0SkUpxzNfaVkJDgAunLL790HTt2POP9jBkzXLt27dzhw4fdvn37XJMmTdyf//xn55xz48ePd1OmTHHOOXf99de7rVu3OuecW716tUtJSXHOORcdHe127tzpnHPu0KFDAa1ZRKQygDTn4z42EF8GV6P8a90u/vfdLezOPkar8IY83Lc9P4g/17dTF0lJSaFx48Y0btyYpk2bMmDAAABiYmLIzMwkNzeXVatWceutt5bMc+LECQB69OjB3XffzW233cbgwYOrZmAiIgFWqwLgX+t28Yv5n3Is/xQAu7KP8Yv5nwJUGAL169cveV+nTp2S6Tp16lBQUEBhYSHh4eFkZGScMe+0adP4+OOPefvtt0lISCA9PZ3mzZsHalgiIlWiVl0D+N93t5Ts/L91LP8U//vuFgAaN27MkSNHzmvZTZo04YorruCf//wnUHTqbP369UDRtYFu3brx+OOP06JFC77++utzLUpEpEaoVUcAu7OPnbO9efPm9OjRg+joaK6++upKL3/27Nnce++9TJ48mfz8fIYPH05cXBwPP/ww27ZtwzlH7969iYurPc+8nzZtGhdddBEjRowIdikiEmC16ttAezz1AbvKCYHLwxvy4YTrA1maiEiN5NlvA324b3sahoaUaWsYGsLDfdsHqaKa6e9//ztdu3alU6dO/PjHP+bUqVOEhYXxy1/+kri4OLp3787evXsBmDRpEs888wwAGRkZdO/endjYWAYNGsShQ4fYvn07nTt3Lln2tm3bSqYnTJhAVFQUsbGxPPTQQ9U/UBE5p1oVAD+Iv5wnB8dweXhDjKJ/+T85OManu4C8YtOmTcydO5cPP/yQjIwMQkJCmD17Nnl5eXTv3p3169fTq1cv/u///u+MeUeMGMHTTz9NZmYmMTEx/OY3v6Fdu3Y0bdq05OL4jBkzGDVqFAcOHGDBggVs2LCBzMxMHnvsseoeqohUoFZdA4CiEPD6Dv9ct8IuWbKE9PR0unTpAsCxY8do2bIl9erV4+abbwYgISGB999/v8wyc3JyyM7OJikpCYCRI0eW3BL7ox/9iBkzZvDss88yd+5c1qxZQ9OmTWnQoAGjR4/m5ptvLlm2iNQcteoIQL67FXZX9jEc390K+691u4Ciu5dGjhxJRkYGGRkZbNmyhUmTJhEaGkrx4zoJCQmhoKDA53UOGTKEd955h7feeouEhASaN29O3bp1WbNmDUOHDuWtt96iX79+VTFcEfGDAqCWqehW2N69ezNv3jz27dsHwMGDB/nvf/9b4XKbNm1Ks2bNWLFiBQB/+9vfSo4GGjRoQN++fbn33nsZNWoUALm5ueTk5JCamsqUKVNKbpkVkZqj1p0C8rqKboWNiopi8uTJ3HjjjRQWFhIaGsoLL7xwzmV+e2Qwa9Ysxo4dy9GjR7nyyiuZMWNGSZ877riDBQsWcOONNwJw5MgRBg4cyPHjx3HO8eyzzwZieCISQAqAWqZVeMNyb4VtFd6w5P2wYcMYNmxYmc9zc3NL3g8dOrTkq7IPHDhA27ZtAejUqROrV68ud70rV65k1KhRhIQU3YV12WWXsWbNGv8GIyJVSqeAaplA3go7ceJEPv74Y2655ZZz9hs0aBCvvPIKP/3pTyu9DhEJnlr1h2BS5Hy/EE9ELnyV+UMwnQKqhXQrrIj4QqeAREQ8SgEgIuJRCgAREY9SAIiIeJQCQETEoxQAIiIepQAQEfEoBYCIiEcpAEREPEoBICLiUfoqCBGRGiJv3T4Ov7uDU9knCAmvT5O+kTSKb1ll61MAiIjUAHnr9pE9fxsuvxCAU9knyJ6/DaDKQkCngEREaoDD7+4o2fl/y+UXcvjdHSXTqamp7N69O2DrDEgAmFk/M9tiZp+b2YRyPjcze77480wz6xyI9YqI1Bansk9U2L5o0SJatWoVsHX6HQBmFgK8APQHooDbzSzqtG79gauKX2OAP/u7XhGR2iQkvH6l2gMhEEcAXYHPnXNfOOdOAnOAgaf1GQi84oqsBsLN7LIArFtEpFZo0jcSCy27S7bQOjTpG1ll6wxEAFwOfF1qemdxW2X7AGBmY8wszczSsrKyAlCeiEjN1yi+JeGDryr5F39IeH3CB1/lrbuAnHPTgelQ9EjIIJcjIlJtGsW3rNId/ukCcQSwC2hTarp1cVtl+4iISDUKRACsBa4ysyvMrB4wHHjztD5vAiOK7wbqDuQ45/YEYN0iInKe/D4F5JwrMLNxwLtACPCyc26DmY0t/nwasAhIBT4HjgKj/F2viIj4JyDXAJxziyjayZdum1bqvQN+Eoh1iYhIYOgvgUVEPEoBICLiUQoAERGPUgCIiHiUAkBExKMUACIiHqUAEBHxKAWAiIhHKQBERDxKASAi4lEKAJEAMTPuvPPOkumCggJatGjBzTfffM75li1bVtJn2bJlrFq1qkrrFPmWAkAkQBo1asRnn33GsWPHAHj//fe5/PJyn3t0VgoAqU4KAJEASk1N5e233wbg1Vdf5fbbby/5bM2aNVxzzTXEx8dz7bXXsmXLljLz7tixg2nTpjFlyhQ6derEihUrWLhwId26dSM+Pp4+ffqwd+/eah2P1G4KAJEAGj58OHPmzOH48eNkZmbSrVu3ks86dOjAihUrWLduHY8//jiPPvpomXkjIyMZO3YsDzzwABkZGVx33XX07NmT1atXs27dOoYPH87vf//76h6S1GI17pGQIjVVzsKF7JvyHAV79lD3ssto+cB4mg4YUKZPbGwsO3bs4NVXXyU1NbXs/Dk5jBw5km3btmFm5OfnV7jOnTt3MmzYMPbs2cPJkye54oorAjom8TYdAYj4IGfhQvZM/BUFu3eDcxTs3s2eib8iZ+HCM/recsstPPTQQ2VO/wBMnDiRlJQUPvvsMxYuXMjx48crXO99993HuHHj+PTTT/nLX/7i0zwivlIAiPhg35TncKftfN3x4+yb8twZfe+55x5+/etfExMTU6Y9Jyen5KLwzJkzy11P48aNOXLkSLnzzJo1y58hiJxBASDig4I95T/Curz21q1bc//995/R/vOf/5xf/OIXxMfHU1BQUO7yBgwYwIIFC0ouAk+aNIlbb72VhIQEIiIi/BuEyGms6GmNNVNiYqJLS0sLdhkibLu+d9Hpn9PUbdWKqz5YEoSKRMpnZunOuURf+uoIQMQHLR8YjzVoUKbNGjSg5QPjg1SRiP90F5CID76926eiu4BELiQKABEfNR0wQDt8qVV0CkhExKMUACIiHqUAEBHxKAWAiIhHKQBERDxKASAi4lEKABERj1IAiIh4lAJARMSjFAAiIh6lABAR8SgFgIiIRykAREQ8SgEgIuJRCgAP++abbxg+fDjt2rUjISGB1NRUtm7dWqllJCcnU5mntj333HMcPXq0sqWKSBXwKwDM7GIze9/MthX/bFZOnzZmttTMNprZBjP7qT/rlMBwzjFo0CCSk5PZvn076enpPPnkk+zdu7dK16sAEKk5/D0CmAAscc5dBSwpnj5dAfAz51wU0B34iZlF+ble8dPSpUsJDQ1l7NixJW1xcXH07NmThx9+mOjoaGJiYpg7d27J508//TQxMTHExcUxYULZ/9SFhYXcfffdPPbYYwDce++9JCYm0rFjR379618D8Pzzz7N7925SUlJISUkB4NVXXyUmJobo6GgeeeSRkuWV137q1CnuvvvuktqmTJlSNRtHxCucc+f9ArYAlxW/vwzY4sM8bwA3+LL8hIQEJ1Xjj3/8oxs/fvwZ7fPmzXN9+vRxBQUF7ptvvnFt2rRxu3fvdosWLXLXXHONy8vLc845d+DAAeecc0lJSe6jjz5yw4cPd5MnTy5ZzrefFxQUuKSkJLd+/XrnnHNt27Z1WVlZzjnndu3a5dq0aeP27dvn8vPzXUpKiluwYMFZ29PS0lyfPn1K1nHo0KGq2TgiFzAgzfm4D/f3COAS59ye4vffAJecq7OZRQLxwMd+rleqyMqVK7n99tsJCQnhkksuISkpibVr17J48WJGjRrFRRddBMDFF19cMs+Pf/xjoqOj+eUvf1nS9tprr9G5c2fi4+PZsGEDGzduPGNda9euJTk5mRYtWlC3bl3uuOMOli9fftb2K6+8ki+++IL77ruPf//73zRp0qTqN4hILVZhAJjZYjP7rJzXwNL9ipPHnWM5YcDrwHjn3OFz9BtjZmlmlpaVlVWJocgZMl+DKdEwKbzoZ+ZrJR917NiR9PT0gKzm2muvZenSpRw/fhyAL7/8kmeeeYYlS5aQmZnJTTfdVPKZP5o1a8b69etJTk5m2rRp/OhHP/J7mSJeVmEAOOf6OOeiy3m9Aew1s8sAin/uK28ZZhZK0c5/tnNufgXrm+6cS3TOJbZo0aLyI5Iima/Bwvsh52vAFf1ceH9JCFx//fWcOHGC6dOnfzdLZibh4eHMnTuXU6dOkZWVxfLly+natSs33HADM2bMKLmAe/DgwZL5Ro8eTWpqKrfddhsFBQUcPnyYRo0a0bRpU/bu3cs777xT0rdx48YcOXIEgK5du/Kf//yH/fv3c+rUKV599VWSkpLO2r5//34KCwsZMmQIkydP5pNPPqmGDSlSe9X1c/43gZHAU8U/3zi9g5kZ8Fdgk3PuWT/XJ75a8jjkHyvbln+sqD32NsyMBQsWMH78eJ5++mkaNGhAZGQkzz33HLm5ucTFxWFm/P73v+fSSy+lX79+ZGRkkJiYSL169UhNTeWJJ54oWfSDDz5ITk4Od911F7NnzyY+Pp4OHTrQpk0bevToUdJvzJgx9OvXj1atWrF06VKeeuopUlJScM5x0003MXBg0YFlee3r169n1KhRFBYWAvDkk09W/XYUqcWs6MzNec5s1hx4Dfge8F/gNufcQTNrBbzknEs1s57ACuBToLB41kedc4sqWn5iYqKrzD3mUsqkcMo/I2cwKbu6qxGRamJm6c65RF/6+nUE4Jw7APQup303kFr8fiVg/qxHzkPT1sWnf8ppFxFBfwlce/X+FYQ2LNsW2rCoXUQEBUDtFXsbDHgemrYBrOjngOeL2kVE8P8isNRksbdphy8iZ6UjABERj1IAiIh4lAJARMSjFAAiIh6lABAR8SgFgIiIRykAREQ8SgEgIuJRCgAREY9SAIiIeJQCQETEoxQAIiIepQAQEfEoBYCIiEcpAEREPEoBICLiUQoAERGPUgCIiHiUAkBExKMUACIiHqUAEBHxKAWAiIhHKQBERDxKASAi4lEKABERj1IAiIh4lAJARMSjFAAiIh6lABAR8SgFgIiIRykAREQ8SgEgEmBmBsDu3bsZOnQoADNnzmTcuHHBLEvkDAoAkSrSqlUr5s2bF+wyRM5KASBSRXbs2EF0dPQZ7W+//TbXXHMN+/fvJysriyFDhtClSxe6dOnChx9+GIRKxavq+jOzmV0MzAUigR3Abc65Q2fpGwKkAbucczf7s16RC9WCBQt49tlnWbRoEc2aNeOHP/whDzzwAD179uSrr76ib9++bNq0Kdhlikf4FQDABGCJc+4pM5tQPP3IWfr+FNgENPFznSIXpA8++IC0tDTee+89mjQp+jVYvHgxGzduLOlz+PBhcnNzCQsLC1aZ4iH+BsBAILn4/SxgGeUEgJm1Bm4Cfgc86Oc6RYJqzZqpHDj4V0JDj5Cf35jmF4+ma9f7KpyvXbt2fPHFF2zdupXExEQACgsLWb16NQ0aNKjqskXO4O81gEucc3uK338DXHKWfs8BPwcK/VyfSFCtWTOV7Jyp1Kt3BDOoV+8I2TlTWbNmaoXztm3bltdff50RI0awYcMGAG688UamTv1u3oyMjCqrXeR0FQaAmS02s8/KeQ0s3c855wBXzvw3A/ucc+m+FGRmY8wszczSsrKyfB2HSLU4cPCvhIScKtMWEnKKAwf/6tP8HTp0YPbs2dx6661s376d559/nrS0NGJjY4mKimLatGlVUbZIuaxov32eM5ttAZKdc3vM7DJgmXOu/Wl9ngTuAgqABhRdA5jvnLuzouUnJia6tLS0865PJNAWL2lH8W3+ZTgHfXpvr/6CRE5jZunOuURf+vp7CuhNYGTx+5HAG6d3cM79wjnX2jkXCQwHPvBl5y9SE+XnN65Uu0hN5m8APAXcYGbbgD7F05hZKzNb5G9xIjVN84tHc+pUSJm2U6dCaH7x6CBVJHL+/DoFVNV0CkhqovO9C0ikOlTmFJC/t4GKeE7Rzl47fLnw6asgREQ8SgEgIuJRCgAREY9SAIiIeJQCQETEo2r0baBmlgX8t1RTBLA/SOUEyoU+BtUfXKo/+Gr6GNo651r40rFGB8DpzCzN1/tba6oLfQyqP7hUf/DVhjF8S6eAREQ8SgEgIuJRF1oATA92AQFwoY9B9QeX6g++2jAG4AK7BiAiIoFzoR0BiIhIgNTIADCzfma2xcw+L37Y/Omfm5k9X/x5ppl1DkadZ+ND/R3M7CMzO2FmDwWjxnPxof47irf7p2a2ysziglHnufgwhoHFY8gofgJdz2DUeTYV1V+qXxczKzCzodVZX0V82P7JZpZTvP0zzOxXwajzbHzZ/sVjyDCzDWb2n+quMSCcczXqBYQA24ErgXrAeiDqtD6pwDuAAd2Bj4NddyXrbwl0AX4HPBTsms+j/muBZsXv+9ek7V+JMYTx3SnQWGBzsOuuTP2l+n0ALAKGBrvuSm7/ZOCtYNfqR/3hwEbge8XTLYNd9/m8auIRQFfgc+fcF865k8AcYOBpfQYCr7giq4Hw4kdS1gQV1u+c2+ecWwvkB6PACvhS/yrn3KHiydVA62qusSK+jCHXFf/mAo0o53nWQeTL7wAUfSf168C+6izOB77WX1P5Uv8PKXq07VdQ9DtdzTUGRE0MgMuBr0tN7yxuq2yfYKnJtfmisvWPpuhorCbxaQxmNsjMNgNvA/dUU22+qLB+M7scGAT8uRrr8pWv/w9dW3wa7h0z61g9pfnEl/q/DzQzs2Vmlm5mI6qtugDSA2HkvJlZCkUBUKPOn/vKObcAWGBmvYDfUvRY0wvFc8AjzrlCK+/0D/xDAAABuElEQVQp9TXfJxSdPsk1s1TgX8BVQa6pMuoCCUBvoCHwkZmtds5tDW5ZlVMTA2AX0KbUdOvitsr2CZaaXJsvfKrfzGKBl4D+zrkD1VSbryr138A5t9zMrjSzCOdcTfiOF1/qTwTmFO/8I4BUMytwzv2reko8pwrrd84dLvV+kZm9eIFt/53AAedcHpBnZsuBOOCCCoCgX4Qo5wJMXeAL4Aq+uwDT8bQ+N1H2IvCaYNddmfpL9Z1EzbsI7Mv2/x7wOXBtsOv1Ywz/j+8uAnem6Bfcgl17Zf8fKu4/k5p1EdiX7X9pqe3fFfjqQtr+wNXAkuK+FwGfAdHBrr2yrxp3BOCcKzCzccC7FF2Nf9k5t8HMxhZ/Po2iux5SKdoJHQVGBave0/lSv5ldCqQBTYBCMxtP0V0Gh8+64Gri4/b/FdAceLH4X6AFrgZ9OZaPYxgCjDCzfOAYMMwV/2YHm4/111g+1j8UuNfMCija/sMvpO3vnNtkZv8GMoFC4CXn3GfBq/r86C+BRUQ8qibeBSQiItVAASAi4lEKABERj1IAiIh4lAJARMSjFAAiIh6lABAR8SgFgIiIR/1/HeTj4qy/3a8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1507d051d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of U: (11, 2)\n",
      "vector for 'likes': [ 0.15663919  0.32849558]\n",
      "vector for 'enjoys': [ 0.15680191  0.09115486]\n",
      "vector for 'good': [ 0.17807516  0.45032677]\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "print(vocab)\n",
    "for word in vocab:\n",
    "    i=w2i[word]\n",
    "    plt.text(U[i,0]+0.01,U[i,1], word)\n",
    "    plt.plot(U[i,0],U[i,1], 'o')\n",
    "plt.show()\n",
    "print(\"size of U:\", U.shape)\n",
    "print(\"vector for 'likes':\", U[w2i[\"likes\"]])\n",
    "print(\"vector for 'enjoys':\", U[w2i[\"enjoys\"]])\n",
    "print(\"vector for 'good':\", U[w2i[\"good\"]])\n",
    "#for w in vocab:\n",
    "#    print(\"vector for '{}': {}\".format(w, U[w2i[w]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Similarity\n",
    "\n",
    "**cosine** similarity \n",
    "\n",
    "<img src=\"https://simonpaarlberg.com/posts/2012-06-28-latent-semantic-analyses/eq1.png\">\n",
    "<img src=\"https://simonpaarlberg.com/posts/2012-06-28-latent-semantic-analyses/vector_example2.png\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Deep learning approach: Directly learning word vectors (embeddings)\n",
    "\n",
    "* SVD: computation cost scales quadratically with size of co-occurence matrix; difficult to integrate new words\n",
    "* **Idea**: directly learn word vectors (word2vec)\n",
    "    * NLP (almost) from Scratch (Collobert & Weston, 2008)\n",
    "    * word2vec (Mikolov et al, 2013)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Main idea of word2vec\n",
    "\n",
    "* instead of capturing co-occurence statistics of words\n",
    "* **predict context** (surrounding words of every word); in particular, predict words in a window of length $m$ around current word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$o$ is the outside word (context), $c$ is the current center word; \n",
    "\n",
    "Maximize the probability of a word in the context ($o$) given the current word $c$:\n",
    "\n",
    "$$p(o|c) = \\frac{exp(u_o^T v_c)}{\\sum_{w=1}^W exp(u_w^T v_c)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"http://www.gabormelli.com/RKB/images/a/a6/skip-gram_NNLM_architecture.150216.jpg\">\n",
    "\n",
    "At the end you can read off the embedding vector from the Embedding layer! voila!\n",
    "\n",
    "NB. denominator $\\sum$ over all words! In practice, *negative sampling* is used (randomly choose a word which is not in context as a negative sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Word Embeddings and `LookupParameters`\n",
    "\n",
    "In deep learning for NLP we typically represent words as vectors.\n",
    "\n",
    "Vectors are of size $d$ (or of d dimensions).\n",
    "\n",
    "**Each feature** is represented as a $d$-dim vector.\n",
    "\n",
    "These are then summed or concatenated to form an input vector.\n",
    "\n",
    "The embeddings can be pre-trained. \n",
    "\n",
    "They are usually trained with the model.\n",
    "\n",
    "The feature vectors are parameters of the model and are trained jointly with the rest of the network. \n",
    "\n",
    "Representation Learning: similar features will receive similar vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**a) sparse representation vs b) dense representation**  (Figure 1 in Yoav Goldberg's primer)\n",
    "<img src=\"pics/sparsevsdense.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Traditional vs deep learning approach to feature extraction (representations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The **traditional** approach for extracting features for an NLP model is:\n",
    "\n",
    "* extract a set of core linguistic features $f_1,..f_n$\n",
    "* define a vector whose length is the total number of features; (n-hot): 1 at position k if the k-th feature is active; this feature vector represents the **instance** $\\mathbf{x}$  (**sparse representation**, n-hot encoding)\n",
    "* use $\\mathbf{x}$ as representation for an instance, train the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Instead, in a neural approach it is typical to:\n",
    "\n",
    "* extract a set of core linguistic features $f_1,..f_n$\n",
    "* define a **vector** for **each feature** (lookup Embedding table)\n",
    "* **combine** vectors of features to get the vector representation for the **instance** $\\mathbf{x}$ (**dense representation**)\n",
    "* use $\\mathbf{x}$ as representation for an instance, train the model\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### How do you combine different feature vector representations?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In an NLP application, $\\mathbf{x}$ is usually composed of various embedding vectors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Following the notation in Goldberg (2015), chapter 4, lets use the function $c(\\cdot)$ as **feature combiner** that creates our input embeddings layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "A common choice for $c$ is **concatenation**:\n",
    "\n",
    "$\\mathbf{x} = c(f_1, f_2, f_3) = [v(f_1); v(f_2); v(f_3)] $\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Alternatively, $c$ could be the **sum of the embeddings vector**:\n",
    "\n",
    "$\\mathbf{x} = c(f_1, f_2, f3) = [v(f_1)+v(f_2)+v(f_3)] $\n",
    "\n",
    "or the **mean**:\n",
    "\n",
    "$\\mathbf{x} = c(f_1, f_2, f3) = [mean(v(f_1),v(f_2),v(f_3))] $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In many papers $v$ is often referred to as the embeddings layer or lookup layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Our example from before with explicit input representation\n",
    "\n",
    "For instance, let us explicitly state the input representation. Suppose we use the concatentation operator, then our network above becomes:\n",
    "\n",
    "<img src=\"pics/nn.png\" width=300> \n",
    "\n",
    "since: \n",
    "$\\mathbf{x} = c(f_1, f_2, f3) = [v(f_1); v(f_2); v(f_3)] $\n",
    "\n",
    "then: \n",
    "\n",
    "$NN_{MLP1}(\\mathbf{x})=g(\\mathbf{[v(f_1); v(f_2); v(f_3)]W^1+b^1})\\mathbf{W^2}+\\mathbf{b^2}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "As computational graph:\n",
    "<img src=\"pics/yg-compgraph2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The values of the *embedding vectors* (values of the vectors in Fig 1 b)) are treated as model parameters and **trained together** with the other parameters of the model (weights)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Unrolled (graph with concrete input, expected output, and loss node, Goldberg Figure 3 c):\n",
    "<img src=\"pics/yg-compgraph3.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## LookupParameters \n",
    "\n",
    "In DyNet, embeddings are implemented using\n",
    "LookupParameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import dynet as dy\n",
    "model = dy.Model()\n",
    "\n",
    "vocab_size = 10000\n",
    "emb_dim = 200\n",
    "E = model.add_lookup_parameters((vocab_size, emb_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "dy.renew_cg()\n",
    "x = dy.lookup(E, 5)\n",
    "# or\n",
    "x = E[5]\n",
    "# x is an expression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### CBOW model\n",
    "\n",
    "A simple classification model that uses an embedding representation, e.g., the sum (or average) of the embeddings of the words in the sentence. It often works surprisingly well.\n",
    "\n",
    "$$ \\mbox{CBOW}(w_i,..,w_n) = \\sum_i^n E[w_i] $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# code from G. Neubig's tutorial\n",
    "model = dy.Model()\n",
    "trainer = dy.AdamTrainer(model)\n",
    "\n",
    "# Define the model\n",
    "EMB_SIZE = 64\n",
    "W_emb = model.add_lookup_parameters((nwords, EMB_SIZE)) # Word embeddings\n",
    "W_sm = model.add_parameters((ntags, EMB_SIZE))          # Softmax weights\n",
    "b_sm = model.add_parameters((ntags))                      # Softmax bias\n",
    "\n",
    "# A function to calculate scores for one value\n",
    "def calc_scores(words):\n",
    "    dy.renew_cg()\n",
    "    cbow = dy.esum([dy.lookup(W_emb, x) for x in words])\n",
    "    W_sm_exp = dy.parameter(W_sm)\n",
    "    b_sm_exp = dy.parameter(b_sm)\n",
    "    return W_sm_exp * cbow + b_sm_exp\n",
    "\n",
    "for ITER in range(100):\n",
    "    # Perform training\n",
    "    random.shuffle(train)\n",
    "    train_loss = 0.0\n",
    "    start = time.time()\n",
    "    for words, tag in train:\n",
    "        my_loss = dy.pickneglogsoftmax(calc_scores(words), tag)\n",
    "        train_loss += my_loss.value()\n",
    "        my_loss.backward()\n",
    "        trainer.update()\n",
    "    print(\"iter %r: train loss/sent=%.4f, time=%.2fs\" % (ITER, train_loss/len(train), time.time()-start))\n",
    "    # Perform testing\n",
    "    test_correct = 0.0\n",
    "    for words, tag in dev:\n",
    "        scores = calc_scores(words).npvalue()\n",
    "        predict = np.argmax(scores)\n",
    "        if predict == tag:\n",
    "              test_correct += 1\n",
    "    print(\"iter %r: test acc=%.4f\" % (ITER, test_correct/len(dev)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Making it deeper\n",
    "<img src=\"pics/deepbow.png\">\n",
    "[Image credit: DyNet tutorial] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Word Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "So, in deep learning approaches to NLP words are represented as dense vectors. Where do these word vectors (embeddings) come from?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* **off-the-shelf embeddings**: you can also use trained, available embeddings (e.g. estimated with *word2vec*) and *initialize* the embedding layer of the network with your pretrained (unsupervised) word embeddings\n",
    "* **task-specific embeddings**: you could also train your embeddings from scratch with the data for your task. In this case, the vectors are typically **randomly initialized** (small numbers around 0) and *trained with the network*. At the end you can read them off the network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Remember, today we have seen tree ways to get embeddings:\n",
    "\n",
    "1. Traditional methods (also called 'count' methods): SVD on a co-occurence matrix (=LSA)\n",
    "2. Neural method #1 (also called 'predict' methods): word2vec (train on large unlabeled corpus)\n",
    "3. Neural method #2 (also a 'predict' method, but task-specific): train your embeddings on your supervised task, read them off at the end (typically less used as you will have less supervised training data, it's easier to get loads of unlabeled text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Inputs of different lengths\n",
    "\n",
    "In our animacy classification example we have one simplification: the input is always of the same size (namely, 5 words). \n",
    "\n",
    "However, in NLP we typically never have fixed size inputs, sentences are of different length. The neural network however needs inputs of fixed size. So how to deal with it?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* create an input of fixed size, like using the mean embedding vector\n",
    "* use a model that can deal with variable size inputs, like a **recurrent neural network** (depending on the deep learning toolkit you use, you might still need to *pad* sequences to a fixed length)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Karpathy's illustration of RNNs:\n",
    "<img src=\"http://benjaminbolte.com/resources/attention_rnn/karpathy_rnn.jpeg\">\n",
    "\n",
    "* From left to right: (1) Vanilla mode of processing without RNN, from fixed-sized input to fixed-sized output (e.g. image classification). (2) Sequence output (e.g. image captioning takes an image and outputs a sentence of words). (3) Sequence input (e.g. sentiment analysis where a given sentence is classified as expressing positive or negative sentiment). (4) Sequence input and sequence output (e.g. Machine Translation: an RNN reads a sentence in English and then outputs a sentence in French). (5) Synced sequence input and output (e.g. video classification where we wish to label each frame of the video). Notice that in every case are no pre-specified constraints on the lengths sequences because the recurrent transformation (green) is fixed and can be applied as many times as we like.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Important concepts: Prediction problems, non-neural baselines\n",
    "\n",
    "In NLP we typically deal with the following **prediction problems** - Given $x$, predict $y$:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "| Given $x$ | predict $y$  | Type of prediction problem | \n",
    "|------|------|\n",
    "|   a book review  | positive, negative | **classification** (binary) |\n",
    "|   a tweet  | language | **multi-class classification** (several choices) |\n",
    "|   a sentence  | its syntactic parse tree | **structured prediction** (millions of choices) |\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "| Example task | Traditional classifier  | Type of prediction problem | \n",
    "|------|------|\n",
    "|   sentiment | Logistic regression, SVM | **classification** (binary) |\n",
    "|   language identification  | Logistic regression, SVM  | **multi-class classification** (several choices) |\n",
    "|   POS sequence  | HMM, structured perceptron, (window-based classifier) | **structured prediction** (millions of choices) |\n",
    "|   NER  | CRF, structured perceptron | **structured prediction** (millions of choices) |\n",
    "\n",
    "\n",
    "Remember: also think about the evaluation measure! Notice: Error detection task uses specific F score (0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### References\n",
    "\n",
    "* Yoav Goldberg's primer chapter 2 and 5: [A Primer on Neural Network Models for Natural Language Processing](http://arxiv.org/abs/1510.00726)\n",
    "* Simon Paarlberg's [blog on LSA](https://simonpaarlberg.com/post/latent-semantic-analyses/)\n",
    "* Richard Socher's [lecture 2](https://www.youtube.com/watch?v=xhHOL3TNyJs)\n",
    "* Graham Neubig's slides on the [structured perceptron](http://www.phontron.com/slides/nlp-programming-en-12-struct.pdf)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
